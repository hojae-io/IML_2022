{"backend_state":"init","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"trust":false,"type":"settings"}
{"cell_type":"code","exec_count":1,"id":"d178f2","input":"%matplotlib inline\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.distance import cdist\nfrom matplotlib import gridspec\nimport cv2\nimport os\nimport time\nfrom preprocessing import PreProcessing\nfrom model import TripletLossetLoss","pos":0,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"a049dc","input":"# Find k nearest neighbour using cosine similarity\ndef find_k_nn(normalized_train_vectors,vec,k):\n    dist_arr = np.matmul(normalized_train_vectors, vec.T)\n    return np.argsort(-dist_arr.flatten())[:k]","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"484106","input":"normalized_training_vectors = generate_db_normed_vectors()","output":{"0":{"name":"stdout","output_type":"stream","text":"WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nINFO:tensorflow:Restoring parameters from ./trained_model/model_triplet/model.ckpt\n"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"4f4478","input":"# Compute vector representation of test image \nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    ckpt = tf.train.get_checkpoint_state(model_path)\n    saver.restore(sess, model_path+\"model.ckpt\")\n    search_vector = sess.run(net, feed_dict={img_placeholder:[im]}) \nnormalized_search_vec = search_vector/np.linalg.norm(search_vector)","output":{"0":{"name":"stdout","output_type":"stream","text":"INFO:tensorflow:Restoring parameters from ./trained_model/model_triplet/model.ckpt\n"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"d6e539","input":"s_time = time.time()\nk = 10\ncandidate_index = find_k_nn(normalized_training_vectors, normalized_search_vec, k)\nprint('Total time to find nn: {:0.2f} ms'.format((time.time()-s_time)*1000))\nfig = plt.figure(figsize=(10, 0.8))\nidxs = [idx]\ngs = gridspec.GridSpec(1, len(idxs))\n# plot test image\nfor i in range(len(idxs)):\n    ax = fig.add_subplot(gs[0, i])\n    ax.imshow(test_images[idxs[i], :, :, :])\n    ax.axis('off')\nplt.show()\n# plot similar images\nshow_image(candidate_index, train_images)\nprint(\"Index of Similar images:\", candidate_index)","output":{"0":{"name":"stdout","output_type":"stream","text":"Total time to find nn: 2.15 ms\n"},"1":{"data":{"image/png":"31534c8fb9978fc997be12b9a298cddab456cb57","text/plain":"<matplotlib.figure.Figure at 0x136f46d68>"},"output_type":"display_data"},"2":{"data":{"image/png":"3d623b53fbb4ffc1a918b078ac07d4c744e331e8","text/plain":"<matplotlib.figure.Figure at 0x13910f940>"},"output_type":"display_data"},"3":{"name":"stdout","output_type":"stream","text":"Index of Similar images: [ 9064  9304  4146 19979  2854 15740  3809  8522  8928  5135]\n"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"049d7c","input":"#helper function to plot imageS\ndef show_top_k_images(indx_list,test_image_indexes, train_data, test_data):\n    fig = plt.figure(figsize=(20, 40))\n    gs = gridspec.GridSpec(len(indx_list),len(indx_list[0])+2)\n    for i in range(len(indx_list)):\n        ax = fig.add_subplot(gs[i,0])\n        ax.imshow(test_data[test_image_indexes[i],:,:,:])\n        ax.axis('off')\n        for j in range(len(indx_list[0])):\n            ax = fig.add_subplot(gs[i,j+2])\n            ax.imshow(train_data[indx_list[i][j],:,:,:])\n            ax.axis('off')\n    plt.savefig('./figures/similar_images.jpg')\n    plt.show()","pos":16,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"08d13f","input":"K = 10\nN = 20\nindx_list = []\ntest_image_indexes = []\n_test_images = []\nfor i in range(N):\n    idx = i\n    test_image_indexes.append(idx)\n    _test_images.append(test_images[idx])\n    #run the test image through the network to get the test features\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    ckpt = tf.train.get_checkpoint_state(model_path)\n    saver.restore(sess, model_path+\"model.ckpt\")\n    search_vectors = sess.run(net, feed_dict={img_placeholder:_test_images})\n    \nnormalized_search_vecs = search_vectors/np.linalg.norm(search_vectors,axis=1).reshape(-1,1)\nfor i in range(len(normalized_search_vecs)):\n    candidate_index = find_k_nn(normalized_training_vectors, normalized_search_vecs[i], K)\n    indx_list.append(candidate_index)","output":{"0":{"name":"stdout","output_type":"stream","text":"INFO:tensorflow:Restoring parameters from ./trained_model/model_triplet/model.ckpt\n"}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"d1a294","input":"print('**Query Image**       *************************** Top %d Similar Images  ***************************' % K)\nshow_top_k_images(indx_list,test_image_indexes, train_images, test_images)","output":{"0":{"name":"stdout","output_type":"stream","text":"**Query Image**       *************************** Top 10 Similar Images  ***************************\n"},"1":{"data":{"image/png":"484e9d3957fb866138184ba53b7a87b78f7a5a7b","text/plain":"<matplotlib.figure.Figure at 0x1390b2898>"},"output_type":"display_data"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"442e09","input":"import faiss","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"f44b1a","input":"def generate_db_index():\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        ckpt = tf.train.get_checkpoint_state(model_path)\n        saver.restore(sess, model_path+\"model.ckpt\")\n        train_vectors = sess.run(net, feed_dict={img_placeholder:train_images})   \n\n    d = train_vectors.shape[1]    # Dimension of vector\n    index = faiss.IndexFlatIP(d)  # Build the index\n    normalized_train_vectors = train_vectors/np.linalg.norm(train_vectors,axis=1).reshape(-1,1)\n    index.add(normalized_train_vectors)  # add vectors to the index\n    print('faiss indexing done...')\n    return index","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"e50311","input":"indexed_db = generate_db_index()","output":{"0":{"name":"stdout","output_type":"stream","text":"INFO:tensorflow:Restoring parameters from ./trained_model/model_triplet/model.ckpt\nfaiss indexing done...\n"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"a07f7d","input":"# Read Dataset. Split into training and test set\ndef get_train_test_dataset(train_test_ratio):\n    data_src = './data_repository/geological_similarity/'\n    X = []\n    y = []\n    for directory in os.listdir(data_src):\n        try:\n            for pic in os.listdir(os.path.join(data_src, directory)):\n                img = cv2.imread(os.path.join(data_src, directory, pic))\n                X.append(np.squeeze(np.asarray(img)))\n                y.append(directory)\n        except:\n            pass\n\n    labels = list(set(y))\n    label_dict = dict(zip(labels, range(len(labels))))\n    Y = np.asarray([label_dict[label] for label in y])\n    shuffle_indices = np.random.permutation(np.arange(len(y)))\n    x_shuffled = []\n    y_shuffled = []\n    for index in shuffle_indices:\n        x_shuffled.append(X[index])\n        y_shuffled.append(Y[index])\n\n    size_of_dataset = len(x_shuffled)\n    n_train = int(np.ceil(size_of_dataset * train_test_ratio))\n    n_test = int(np.ceil(size_of_dataset * (1 - train_test_ratio)))\n    return np.asarray(x_shuffled[0:n_train]), np.asarray(x_shuffled[n_train + 1:size_of_dataset]), np.asarray(y_shuffled[0:n_train]), np.asarray(y_shuffled[\n                                                                                                  n_train + 1:size_of_dataset])","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"d7caa0","input":"#run the test image through the network to get the test features\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    ckpt = tf.train.get_checkpoint_state(model_path)\n    saver.restore(sess, model_path+\"model.ckpt\")\n    search_vector = sess.run(net, feed_dict={img_placeholder:[im]})\n    \ns_time = time.time()\nnormalized_search_vec = search_vector/np.linalg.norm(search_vector)\nk = 10\n\n_, candidate_index = indexed_db.search(normalized_search_vec,k)\nprint('Total time to find nn: {:0.2f} ms'.format((time.time()-s_time)*1000))\n\nfig = plt.figure(figsize=(0.8, 0.8))\nidxs = [idx]\ngs = gridspec.GridSpec(1, len(idxs))\n# Display test image\nfor i in range(len(idxs)):\n    ax = fig.add_subplot(gs[0, i])\n    ax.imshow(test_images[idxs[i], :, :, :])\n    ax.axis('off')\nplt.show()\n# Display similar images\nshow_image(candidate_index[0], train_images)\nprint(\"Index of Similar images:\", candidate_index[0])","output":{"0":{"name":"stdout","output_type":"stream","text":"INFO:tensorflow:Restoring parameters from ./trained_model/model_triplet/model.ckpt\nTotal time to find nn: 13.52 ms\n"},"1":{"data":{"image/png":"5a98779ab00affcfba4d12d9d996fa1c4e2319f1","text/plain":"<matplotlib.figure.Figure at 0x140e07390>"},"output_type":"display_data"},"2":{"data":{"image/png":"3d623b53fbb4ffc1a918b078ac07d4c744e331e8","text/plain":"<matplotlib.figure.Figure at 0x142d4bf28>"},"output_type":"display_data"},"3":{"name":"stdout","output_type":"stream","text":"Index of Similar images: [ 9064  9304  4146 19979  2854 15740  3809  8522  8928  5135]\n"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"ad73fc","input":"train_images, test_images, train_label, test_label = get_train_test_dataset(0.7)","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"ce3df7","input":"model = TripletLoss()","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"61818c","input":"#helper function to plot image\ndef show_image(idxs, data):\n    if type(idxs) != np.ndarray:\n        idxs = np.array([idxs])\n    fig = plt.figure()\n    gs = gridspec.GridSpec(1,len(idxs))\n    for i in range(len(idxs)):\n        ax = fig.add_subplot(gs[0,i])\n        ax.imshow(data[idxs[i],:,:,:])\n        ax.axis('off')\n    plt.show()","pos":3,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"65c9e2","input":"model_path = './trained_model/model_triplet/'","pos":5,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"2658e2","input":"# Input and Output Tensor\nimg_placeholder = tf.placeholder(tf.float32, [None, 28, 28, 3], name='img')\nnet = model.conv_net(img_placeholder, reuse=False)","output":{"0":{"name":"stdout","output_type":"stream","text":"\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\nIf you depend on functionality not listed there, please file an issue.\n\nWARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.flatten instead.\n"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"7489e4","input":"# Generate random index from test_images corpus and display the image\nidx = np.random.randint(0, len(test_images))\nim = test_images[idx]\n\n#show the test image\nprint(\"********** QUERY IMAGE **********\")\nshow_image(idx, test_images)","output":{"0":{"name":"stdout","output_type":"stream","text":"********** QUERY IMAGE **********\n"},"1":{"data":{"image/png":"9050b4905e52d30720aa85fc2c7507e16a18c02e","text/plain":"<matplotlib.figure.Figure at 0x12f534a20>"},"output_type":"display_data"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"36cc4a","input":"# Compute Vector representation for each training images and normalize those\ndef generate_db_normed_vectors():\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        ckpt = tf.train.get_checkpoint_state(model_path)\n        saver.restore(sess, model_path+\"model.ckpt\")\n        train_vectors = sess.run(net, feed_dict={img_placeholder:train_images})      \n    normalized_train_vectors = train_vectors/np.linalg.norm(train_vectors,axis=1).reshape(-1,1)\n    return normalized_train_vectors","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"04c93b","input":"## Find k nearest neighbour using cosine similarity [slower]","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"6062c4","input":"## Triplet Loss","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"d10fe7","input":"## Find k nearest neighbour using faiss [faster]","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"d5389c","input":"## VISUALIZATION ","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"e04877","input":"### prerequisite: faiss [install conda distribution: {conda install -c pytorch faiss-cpu}]","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"ffda01","input":"                           ---------------------- *** --------------------","pos":25,"type":"cell"}
{"id":0,"time":1622710268726,"type":"user"}
{"last_load":1622710269949,"type":"file"}