{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-b3035e44-eb1d-4fe9-a2cd-f0eec3e81795.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"orig_nbformat":2},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"188a7f","input":"# triplet_model.fit_generator(data_generator(), steps_per_epoch=150, epochs=10)\n# triplet_model.save(\"triplet.h5\")","pos":14,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"501188","input":"","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"5b499c","input":"# # save numpy array as npy file\n# np.save('Features.npy', vec_tmp_test)\n\n\n# load numpy array from npy file, this file is already saved\nvec_tmp_test = np.load('Features.npy')\nvec_tmp_test.shape","output":{"0":{"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-663db0d38e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# load numpy array from npy file, this file is already saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvec_tmp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Features.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mvec_tmp_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"874a42","input":"# # print(mpimg.imread('./food/00000.jpg')[0])\n# # print(cv2.imread('./food/00000.jpg')[0])\n# kk = cv2.imread('./food/00001.jpg')\n# kk = cv2.resize(kk,(224,224))\n# from PIL import Image\n# pp = Image.fromarray(kk,\"RGB\")\n# pp.show()\n\n# plt.imshow(kk)\n# plt.show()","pos":0,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"d7f367","input":"# class_nbr = 2\n\n# base_model = VGG16(weights='imagenet', include_top=False, input_tensor = Input(shape=(224, 224, 3)))\n\n# # add a global spatial average pooling layer\n# x = base_model.output\n# x = GlobalAveragePooling2D()(x)\n# # let's add a fully-connected layer\n# x = Dense(1024, activation='relu')(x)\n# # and a logistic layer -- let's say we have 200 classes\n# predictions = Dense(class_nbr, activation='softmax')(x)\n\n# # this is the model we will train\n# model = Model(inputs=base_model.input, outputs=predictions)\n\n# # first: train only the top layers (which were randomly initialized)\n# # i.e. freeze all convolutional InceptionV3 layers\n# for layer in base_model.layers:\n#     layer.trainable = False\n\n# # compile the model (should be done *after* setting layers to non-trainable)\n# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n# model.summary()\n","pos":10,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"71314c","input":"# def tripletloss(y_true, y_pred):\n#     anchor_out = y_pred[:, 0:100]\n#     positive_out = y_pred[:, 100:200]\n#     negative_out = y_pred[:, 200:300]\n\n#     pos_dist = K.sum(K.abs(anchor_out - positive_out), axis=1)\n#     neg_dist = K.sum(K.abs(anchor_out - negative_out), axis=1)\n\n#     prob = K.softmax([pos_dist,neg_dist], axis=0)\n#     return K.mean(K.abs(prob[0]) + K.abs(1.0 - prob[1]))","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"1e1fab","input":"# import random\n# def data_generator(batch_size=64):\n#     while True:\n#         a = []\n#         p = []\n#         n = []\n#         for _ in range(batch_size):\n#             pos_neg = random.sample(classes, 2)\n#             pos_sample = random.sample(list(x_train[y_train==pos_neg[0]]), 2)\n#             neg_sample = random.choice(list(x_train[y_train==pos_neg[1]]))\n#             a.append(pos_sample[0])\n#             p.append(pos_sample[1])\n#             n.append(neg_sample)\n#         yield ([np.array(a) , np.array(p) , np.array(n)], np.zeros((batch_size, 1)).astype(\"float32\"))","pos":12,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"40bda8","input":"# triplet_model_a = Input((224,224,3))\n# triplet_model_p = Input((224,224,3))\n# triplet_model_n = Input((224,224,3))\n\n# triplet_model_out = Concatenate()([model(triplet_model_a) , model(triplet_model_p) , model(triplet_model_n)])\n# triplet_model = Model([triplet_model_a , triplet_model_p , triplet_model_n], triplet_model_out)\n# triplet_model.summary()\n# triplet_model.compile(loss=tripletloss, optimizer= \"adam\")","output":{"0":{"name":"stdout","output_type":"stream","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nmodel (Functional)              (None, 2)            15242050    input_2[0][0]                    \n                                                                 input_3[0][0]                    \n                                                                 input_4[0][0]                    \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 6)            0           model[0][0]                      \n                                                                 model[1][0]                      \n                                                                 model[2][0]                      \n==================================================================================================\nTotal params: 15,242,050\nTrainable params: 527,362\nNon-trainable params: 14,714,688\n__________________________________________________________________________________________________\n"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"a5ad3e","input":"# creating a subset of the training data (file with the triplet)\n\nTrain = []\nTrain_concat = df_train.to_numpy()\n\nfor idx in range(len(Train_concat)):\n    a = Train_concat[idx][0][0:5]\n    b = Train_concat[idx][0][6:11]\n    c = Train_concat[idx][0][12:17]\n    array = np.array([a,b,c])\n    Train.append(array)\nTrain = np.array(Train)\nTrain_red = Train[:300]     # subset of the training data (faster to train the model to get a first view of the classifier)\nprint(Train[0])\nprint(Train[0,0])","output":{"0":{"name":"stdout","output_type":"stream","text":"['02461' '03450' '02678']\n02461\n"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"4f2b7c","input":"# Here we take a fully trained model which will compute the feature vectors\n\nbase_model = VGG16(weights='imagenet', include_top=False, input_tensor = Input(shape=(224, 224, 3)))\nx = base_model.output\npredictions = GlobalAveragePooling2D()(x)\nmodel_fully_trained = Model(inputs=base_model.input, outputs=predictions)   #fully trained model\n#  freeze all layers\nfor layer in model_fully_trained.layers:\n    layer.trainable = False\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel_fully_trained.compile(optimizer='adam', loss='categorical_crossentropy')\nmodel_fully_trained.summary()","output":{"0":{"name":"stdout","output_type":"stream","text":"Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 512)               0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 0\nNon-trainable params: 14,714,688\n_________________________________________________________________\n"}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"df9fe5","input":"# vec_tmp_test = model_fully_trained.predict(X)   # DO NOT RUN THIS BLOCK, READ COMMENT OF THE NEXT ONE\n# (vec_tmp_test).shape                            # because it takes 15min to compute predictions","output":{"0":{"name":"stdout","output_type":"stream","text":"(2, 224, 224, 3)\n"},"1":{"data":{"text/plain":"(10000, 512)"},"exec_count":19,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"06ae39","input":"# import all libraries\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import *\n\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom pathlib import Path\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","pos":2,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"93186a","input":"# S_dir = pd.Series(list(data_dir.glob('food/*')))\n# S_dir.drop(0, inplace=True)\n\n# df_dir = pd.DataFrame.from_dict(train_dir)\n# df_dir.drop(0, axis=0, inplace=True)\n# df_dir.reset_index(drop=True, inplace=True)","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"df5c15","input":"# model_embeddings = triplet_model.layer[3].predict(x_test, verbose=1)\n# print(model_embeddings.shape)","pos":15,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"073ebc","input":"Train0 = []\nTrain1 = []\n\nfor i in range(len(Train_red)):     # creating 1 feature vector for each triplet (the feature vect from each of the 3 img are now 1)\n    yoyo0 = np.concatenate((vec_tmp_test[int(Train_red[i,0])], vec_tmp_test[int(Train_red[i,1])], vec_tmp_test[int(Train_red[i,2])]))\n    yoyo1 = np.concatenate((vec_tmp_test[int(Train_red[i,0])], vec_tmp_test[int(Train_red[i,2])], vec_tmp_test[int(Train_red[i,1])]))\n\n    Train0.append(yoyo0)            # each triplet becomes 1 big vector, we stack them.\n    Train1.append(yoyo1)            # since we took a subset of 300 triplet, we stacked 300 feature vector","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"aa316e","input":"Train_Final_tuple_red = tuple(map(tuple, Train_Final_red))      #tried to convert features and labels in \"tuple\" type\nLabel_Final_tuple_red = tuple(Label_Final_red)","pos":23,"tags":{},"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"1bf32f","input":"model = Sequential([Dense(512, input_dim=1536, activation=\"relu\"),  #not trained model, we will train it from scratch\n                    Dense(256, activation=\"relu\"),\n                    Dense(128, activation=\"relu\"),\n                    Dense(2, activation=\"softmax\")\n                    ])\nmodel.compile(\n  optimizer=\"adam\",\n  loss='categorical_crossentropy',\n  metrics=['accuracy'])\n\nmodel.summary()\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 512)               786944    \n_________________________________________________________________\ndense_7 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_9 (Dense)              (None, 2)                 258       \n=================================================================\nTotal params: 951,426\nTrainable params: 951,426\nNon-trainable params: 0\n_________________________________________________________________\n"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":39,"id":"9744bd","input":"# THIS IS JUST A CODE FROM ANOTHER PROBLEM I USED TO CHECK WHAT TYPES THE FEATURES AND LABEL SHOULD HAVE BEFORE USING model.fit()\n\n# import mnist\n# # The first time you run this might be a bit slow, since the\n# # mnist package has to download and cache the data.\n# train_images = mnist.train_images()\n# train_labels = mnist.train_labels()\n\n# print(train_images.shape) # (60000, 28, 28)\n# print(train_labels.shape) # (60000,)","output":{"0":{"name":"stdout","output_type":"stream","text":"(60000, 28, 28)\n(60000,)\n"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"9bfe04","input":"img = mpimg.imread('./food/00001.jpg')\nimgplot = plt.imshow(img)\nplt.show()\nprint(img.shape)","output":{"0":{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './food/00001.jpg'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-15518f458e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./food/00001.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimgplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './food/00001.jpg'"]}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":40,"id":"fadaee","input":"# train_images = mnist.train_images()\n# train_labels = mnist.train_labels()\n# test_images = mnist.test_images()\n# test_labels = mnist.test_labels()\n\n# # Normalize the images.\n# train_images = (train_images / 255) - 0.5\n# test_images = (test_images / 255) - 0.5\n\n# # Flatten the images.\n# train_images = train_images.reshape((-1, 784))\n# test_images = test_images.reshape((-1, 784))\n\n# print(train_images.shape) # (60000, 784)\n# print(test_images.shape)  # (10000, 784)","output":{"0":{"name":"stdout","output_type":"stream","text":"(60000, 784)\n(10000, 784)\n"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"ab823a","input":"IMAGE_SHAPE = (224, 224)\ndata_dir = Path('')\n\nlist(data_dir.glob('*/*.jpg'))[:5]\n\nimage_count = (list(data_dir.glob('*/*.jpg')))\nprint(image_count[0])\n\nfood = list(data_dir.glob('food/*'))","output":{"0":{"name":"stdout","output_type":"stream","text":"food\\00000.jpg\n"}},"pos":4,"tags":{},"type":"cell"}
{"cell_type":"code","exec_count":50,"id":"f904db","input":"# print(type(train_labels[0]))\n# print(train_labels.shape)\n\n# print(type(Label_Final_red[0]))\n# print(Label_Final_red.shape)","output":{"0":{"name":"stdout","output_type":"stream","text":"<class 'numpy.uint8'>\n(60000,)\n<class 'numpy.float64'>\n(600,)\n"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":55,"id":"e6f555","input":"Train0 = np.array(Train0)\nTrain1 = np.array(Train1)\n\nTrain_Final_red = np.concatenate((Train0,Train1))   # feature set composed of label 0 and label 1 (they are not mixed yet so \nTrain_Final_red.shape                               # need to shuffle later)\n\nLabel0 = np.zeros(300, dtype=\"uint8\")           # creating the labels\nLabel1 = np.ones(300, dtype=\"uint8\")\nLabel_Final_red = np.concatenate((Label0,Label1))\n\nrandom.seed(42)                                 # shuffle\nrandom.shuffle(Train_Final_red)\nrandom.shuffle(Label_Final_red)\n\nprint(\"Train_Final_red.shape = \", Train_Final_red.shape)\nprint(\"Label_Final_red.shape = \", Label_Final_red.shape)\ntype(Train_Final_red)","output":{"0":{"name":"stdout","output_type":"stream","text":"Train_Final_red.shape =  (600, 1536)\nLabel_Final_red.shape =  (600,)\n"},"1":{"data":{"text/plain":"numpy.ndarray"},"exec_count":55,"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":59,"id":"80249c","input":"model.fit(Train_Final_red, Label_Final_red, epochs=5, batch_size=3)     #error everytime I dont know why","output":{"0":{"name":"stdout","output_type":"stream","text":"Epoch 1/5\n"},"1":{"ename":"ValueError","evalue":"in user code:\n\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (3, 1) and (3, 2) are incompatible\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-59-fbc5fa59ed0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_Final_red\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabel_Final_red\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\a4009\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (3, 1) and (3, 2) are incompatible\n"]}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"16d229","input":"train_dir = {'food': list(data_dir.glob('food/*'))} #contains the path to every image\naa = train_dir[\"food\"].pop(0)       # there is one weird file which is not an image so i just got rid of it with this line\nprint(train_dir[\"food\"][:5])","output":{"0":{"name":"stdout","output_type":"stream","text":"[WindowsPath('food/00000.jpg'), WindowsPath('food/00001.jpg'), WindowsPath('food/00002.jpg'), WindowsPath('food/00003.jpg'), WindowsPath('food/00004.jpg')]\n"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":64,"id":"24d0f2","input":"X = []       #creating the array which will contain the images (224,224,3) \n\nfor categoryy, images in train_dir.items():     # 20 sec to compute\n    for imaaage in images:\n        img = cv2.imread(str(imaaage))\n        resized_img = cv2.resize(img,(224,224))\n        X.append(resized_img)\n        #y.append(flowers_labels_dict[categoryy])\n\nX = np.array(X)\nX = X/255    #15 sec to compute","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":65,"id":"6a9ebb","input":"X.shape","output":{"0":{"data":{"text/plain":"(10000, 224, 224, 3)"},"exec_count":65,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"082388","input":"# here, verify that the first 5 images in X are image 00000, 00001, 00002, 00003, 00004\n# after verification it is good, but weird colors (coming from cv2)\n\n# plt.imshow(X[0], interpolation='nearest')\n# plt.show()\n# imgplot = plt.imshow( mpimg.imread('./food/00000.jpg') )\n# plt.show()\n\n# plt.imshow(X[1], interpolation='nearest')\n# plt.show()\n# imgplot = plt.imshow( mpimg.imread('./food/00001.jpg') )\n# plt.show()\n\n# plt.imshow(X[2], interpolation='nearest')\n# plt.show()\n# imgplot = plt.imshow( mpimg.imread('./food/00002.jpg') )\n# plt.show()\n\n# plt.imshow(X[3], interpolation='nearest')\n# plt.show()\n# imgplot = plt.imshow( mpimg.imread('./food/00003.jpg') )\n# plt.show()\n\n# plt.imshow(X[4], interpolation='nearest')\n# plt.show()\n# imgplot = plt.imshow( mpimg.imread('./food/00004.jpg') )\n# plt.show()\n\nplt.imshow(X[2888])\nplt.show()\nimgplot = plt.imshow( mpimg.imread('./food/02888.jpg') )\nplt.show()\n\n\n","output":{"0":{"data":{"image/png":"cc43966f2b4f56bd0c40cca4dee5040c7d5483ee","image/svg+xml":"b7042853a745f25004ecf81700da548a4b71c19b","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":8,"metadata":{"needs_background":"light"},"output_type":"execute_result"},"1":{"data":{"image/png":"5f9a624c0d78c038d84b31f819da9f09ab649001","image/svg+xml":"93be7343f1b7d13c9ea75b38845b9edb53c9d062","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":8,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"29c7d4","input":"# Read data\ndf_train = pd.read_csv(\"train_triplets.txt\", header = None)\ndf_test = pd.read_csv(\"test_triplets.txt\", header = None)\n# print(\"df train\",df_train)\n# print(\"df test\",df_test)","pos":9,"type":"cell"}
{"id":0,"time":1643383890069,"type":"user"}
{"last_load":1643387455400,"type":"file"}